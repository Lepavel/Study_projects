{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2hbvbTNLjGj"
   },
   "source": [
    "# Linear Regression\n",
    "+ Simple linear regression with SGD optimization.\n",
    "+ Predict house price with information on number of rooms and age.\n",
    "+ Data: 7 year old house with 3 bedrooms costs 50 thousand dollars, 5 year old house with 5 bedrooms costs 100 thousand dollars.\n",
    "+ Problem: How much would 5 year old house with 4 bedrooms be ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnNgjx7GNt37"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F6hGi4R2LjGp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "eta = 0.5    # learning rate\n",
    "epoch = 1000 # iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XH50w1dLjGq"
   },
   "source": [
    "### Neural Network Model for Linear Regression\n",
    "+ Single layer neural network with linear activation function.\n",
    "+ In forward processing, it uses MSE (mean square error) loss function.\n",
    "+ In backward processing, delta = output - target. \n",
    "+ Backward processing is called \"backprop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JhxbFe39LjGr"
   },
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, x, w, y):\n",
    "        self.inputs  = x\n",
    "        self.weights = w               \n",
    "        self.target  = y\n",
    "        self.output  = np.zeros(self.target.shape)\n",
    "\n",
    "    def forward_proc(self):\n",
    "        # forward processing of inputs and weights\n",
    "        self.output = np.dot(self.weights, self.inputs.T)\n",
    "\n",
    "    def backprop(self):\n",
    "        # backward processing of appling the chain rule to find derivative of the mean square error function with respect to weights\n",
    "        dw = (self.output - self.target) * self.inputs\n",
    "\n",
    "        # update the weights with the derivative of the loss function\n",
    "        self.weights -= eta * dw\n",
    "\n",
    "    def predict(self, x):\n",
    "        # predict the output for a given input x\n",
    "        return (np.dot(self.weights, x.T))\n",
    "        \n",
    "    def calculate_error(self):\n",
    "        # calculate error\n",
    "        error = self.target - self.output\n",
    "        return abs(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndhVGNuGNrYO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmDNen6SLjGr"
   },
   "source": [
    "### SGD (Stochastic Gradient Descent) Optimization\n",
    "+ Train the neural net with SGD optimization.\n",
    "+ In SGD, each input data is trained separately with other input data.\n",
    "+ After training, the weights of the neural network are adjusted to generate the target data for the given input data.\n",
    "+ Check how the loss decreases as the iterations increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdlapqG9LjGs",
    "outputId": "3cd2dfe6-9514-4d8b-d307-c1b88679b667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights: [[0.8569124  0.55925271]]\n",
      "Loss:  [86.9540551]\n",
      "Loss:  [12.44001809]\n",
      "Loss:  [4.19855423]\n",
      "Loss:  [1.39861826]\n",
      "Loss:  [0.44607043]\n",
      "Loss:  [0.13106096]\n",
      "Loss:  [0.04455572]\n",
      "Loss:  [0.01778179]\n",
      "Loss:  [0.00599691]\n",
      "Loss:  [0.0017994]\n",
      "Loss:  [0.00060294]\n",
      "Loss:  [0.00020559]\n",
      "Loss:  [6.94425896e-05]\n",
      "Loss:  [2.55901813e-05]\n",
      "Loss:  [8.19905972e-06]\n",
      "Loss:  [2.8298237e-06]\n",
      "Loss:  [8.24283816e-07]\n",
      "Loss:  [2.80412024e-07]\n",
      "Loss:  [9.64284936e-08]\n",
      "Loss:  [3.43371767e-08]\n",
      "Output: [50.00000001]\n",
      "Adjusted Weights: [[224.99999994 -24.99999996]]\n",
      "Price for 4 beds and 6 years old is predictd as: [[75.]]\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # data normalization on number of rooms and age of the house\n",
    "    input_data = np.array(\n",
    "                  [[.3, .7, 50],\n",
    "                   [.5, .5, 100]])\n",
    "    weights = np.random.rand(1, 2)\n",
    "    print(\"Initial Weights:\", weights)\n",
    "\n",
    "    # SGD Optimization\n",
    "    for i in range(epoch):\n",
    "   \n",
    "        if i == 0: w = weights       \n",
    "\n",
    "        np.random.shuffle(input_data) # shuffle the input data\n",
    "        X = input_data[:, 0:2]\n",
    "        y = input_data[:, 2:3]\n",
    "\n",
    "        for j in range(len(input_data)):\n",
    "         \n",
    "            model = LinearRegression(X[j], w, y[j])\n",
    "            model.forward_proc()   # forward processing\n",
    "            model.backprop()       # backward processing\n",
    "            w = model.weights \n",
    "\n",
    "        if (i % 50) == 0:\n",
    "             print(\"Loss: \", model.calculate_error())\n",
    "        \n",
    "    print(\"Output:\", model.output)\n",
    "    print(\"Adjusted Weights:\", model.weights)\n",
    "\n",
    "    # Prediction\n",
    "    new_data = np.array([[.4, .6]])\n",
    "    print(\"Price for 4 beds and 6 years old is predictd as:\", model.predict(new_data))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grwJciLULjGt"
   },
   "source": [
    "### Testing and Prediction \n",
    "+ After training, you can verify that the required target is generated for a given input data.\n",
    "+ During testing phase, new input data is feeded to check the output.\n",
    "+ With new input data, the output is predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WjQ5I7cLjGt",
    "outputId": "b20c7119-b662-426c-8f65-108b6f552c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for the input data [.3, 0.7]: [[50.00000001]]\n",
      "Output for the input data [.5, 0.5]: [[99.99999999]]\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled):  [[0.4 0.6]]\n",
      "Output:  [[75.]]\n"
     ]
    }
   ],
   "source": [
    "    # verify the output with the adjusted weights\n",
    "    x1 = np.array([[0.3, 0.7]])\n",
    "    print (\"Output for the input data [.3, 0.7]:\", model.predict(x1))\n",
    "    x2 = np.array([[0.5, 0.5]])\n",
    "    print (\"Output for the input data [.5, 0.5]:\", model.predict(x2))\n",
    "    \n",
    "    # predicting and testing the output for a given input data\n",
    "    x_prediction = np.array([[0.4, 0.6]])\n",
    "    predicted_output = model.predict(x_prediction)\n",
    "    print(\"Predicted data based on trained weights: \")\n",
    "    print(\"Input (scaled): \", x_prediction)\n",
    "    print(\"Output: \", predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Lp5wgh5CLjGu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "name": "linear regression (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
