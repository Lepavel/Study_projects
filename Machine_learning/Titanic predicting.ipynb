{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "eta = 0.01   # learning rate\n",
    "epoch = 1500 # iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "# Logistic Regression Model\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, x, w, y):\n",
    "        self.inputs  = x\n",
    "        self.weights = w               \n",
    "        self.target  = y\n",
    "        self.output  = np.zeros(self.target.shape)\n",
    "\n",
    "    def forward_proc(self):\n",
    "       # forward processing of inputs and weights using sigmoid activation function \n",
    "        self.output = sigmoid(np.dot(self.weights, self.inputs.T))\n",
    "\n",
    "    def backprop(self):\n",
    "        # backward processing of appling the chain rule to find derivative of the mean square error function with respect to weights\n",
    "        dw = (self.output - self.target) * self.inputs # same formular for both linear and logistic regression\n",
    "\n",
    "        # update the weights with the derivative of the loss function\n",
    "        self.weights -= eta * dw\n",
    "\n",
    "    def predict(self, x):\n",
    "        # predict the output for a given input x\n",
    "        return (sigmoid(np.dot(self.weights, x.T)))\n",
    "        \n",
    "    def calculate_error(self):\n",
    "        # calculate error\n",
    "        error = -self.target * math.log(self.output) - (1-self.target) * math.log(1-self.output)\n",
    "        return abs(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights: [[0.50541821 0.35593132 0.72694152]]\n",
      "Loss:  [0.42687431]\n",
      "Loss:  [0.89277286]\n",
      "Loss:  [0.20034853]\n",
      "Loss:  [0.0926067]\n",
      "Loss:  [0.2411087]\n",
      "Loss:  [0.90807465]\n",
      "Loss:  [0.09138899]\n",
      "Loss:  [0.1060396]\n",
      "Loss:  [0.87500321]\n",
      "Loss:  [0.09314394]\n",
      "Loss:  [0.09899494]\n",
      "Loss:  [0.09045552]\n",
      "Loss:  [0.09694965]\n",
      "Loss:  [0.46865429]\n",
      "Loss:  [0.24601882]\n",
      "Adjusted Weights: [[ 2.63434658 -1.00998857 -1.98151406]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    # load dataset\n",
    "    df = pd.read_csv(\"titanic_data.csv\")\n",
    "    \n",
    "    # preprocess dataset by changing the string to integer, and filling in the missing values\n",
    "    df['Sex'] = df['Sex'].map({'female':1,'male':0})\n",
    "    df['Age'].fillna(value=df['Age'].mean(), inplace=True)\n",
    "\n",
    "    # initially experiment with 100 samples. For final run, use full dataset\n",
    "    #df = df.iloc[:100, :]\n",
    "    \n",
    "    # select proper features for prediction\n",
    "    passengers = df[[\"Sex\", \"Age\", \"Pclass\",\"Survived\" ]]\n",
    "\n",
    "    weights = np.random.rand(1, 3)\n",
    "    print(\"Initial Weights:\", weights)\n",
    "    \n",
    "    # split train and test set\n",
    "    train, test = train_test_split(passengers, test_size=0.2)\n",
    "    \n",
    "    # select proper features for prediction\n",
    "    train_features = train[[\"Sex\", \"Age\", \"Pclass\"]].values\n",
    "    test_features = test[[\"Sex\", \"Age\", \"Pclass\"]].values\n",
    "    train_labels = train[[\"Survived\"]].values\n",
    "    test_labels = test[[\"Survived\"]].values\n",
    "    \n",
    "    # normalize data\n",
    "    #scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler()\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    test_features = scaler.fit_transform(test_features)\n",
    "    \n",
    "    \n",
    "    # Performance measure\n",
    "    # use the test features\n",
    "    X = test_features\n",
    "    y = test_labels\n",
    "    w = weights # use the weights resulting from training\n",
    "    y_predic = []\n",
    "    for j in range(len(X)):\n",
    "        model = LogisticRegression(X[j], w, y[j])\n",
    "        if model.predict(X[j]) >= 0.5:\n",
    "            y_predic.append(1)\n",
    "        elif model.predict(X[j]) < 0.5:\n",
    "            y_predic.append(0)\n",
    "            \n",
    "    for i in range(epoch):\n",
    "   \n",
    "        if i == 0: w = weights\n",
    "\n",
    "        concat_data=np.concatenate((train_features, train_labels), axis = 1)\n",
    "        np.random.shuffle(concat_data) # shuffle the training dataset\n",
    "        # divide shuffled dataset to features X and labels y\n",
    "        X = concat_data[:, 0:3]\n",
    "        y = concat_data[:, 3:4]\n",
    "        # eta *= 0.95  # decreasing learning rate is found to be not good for this case\n",
    "\n",
    "        for j in range(len(X)): \n",
    "\n",
    "            model = LogisticRegression(X[j], w, y[j])\n",
    "            model.forward_proc()   # forward processing\n",
    "            model.backprop()       # backward processing\n",
    "            w = model.weights \n",
    "\n",
    "        if (i % 100) == 0:\n",
    "             print(\"Loss: \", model.calculate_error())\n",
    "\n",
    "    #print(\"Output:\", model.output)\n",
    "    print(\"Adjusted Weights:\", model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for the input data [0.4, 1.0, 0.6]: [[0.1619917]]\n",
      "Output for the input data [1.0, 0.3, 0.5]: [[0.7347245]]\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled):  [[0.7 0.8 0.4]]\n",
      "Output probability is :  [[0.43869233]]\n",
      "Predicted output is Fail.\n"
     ]
    }
   ],
   "source": [
    "# verify the output with the adjusted weights\n",
    "x1 = np.array([[0.4, 1.0, 0.6]])\n",
    "print (\"Output for the input data [0.4, 1.0, 0.6]:\", model.predict(x1))\n",
    "x2 = np.array([[1.0, 0.3, 0.5]])\n",
    "print (\"Output for the input data [1.0, 0.3, 0.5]:\", model.predict(x2))\n",
    "\n",
    "# predicting and testing the output for a given input data\n",
    "x_prediction = np.array([[0.7, 0.8, 0.4]])\n",
    "predicted_output = model.predict(x_prediction)\n",
    "print(\"Predicted data based on trained weights: \")\n",
    "print(\"Input (scaled): \", x_prediction)\n",
    "print(\"Output probability is : \", predicted_output)\n",
    "if predicted_output >= 0.5:\n",
    "    print(\"Predicted output is PASS.\")\n",
    "elif predicted_output < 0.5:\n",
    "    print(\"Predicted output is Fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0 109]\n",
      " [  0  70]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion = confusion_matrix(test_labels, y_predic)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[  0 108]\n",
      " [  0  71]]\n",
      "Accuracy Score is 0.39664804469273746\n",
      "F1-score: 0.57\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       108\n",
      "           1       0.40      1.00      0.57        71\n",
      "\n",
      "    accuracy                           0.40       179\n",
      "   macro avg       0.20      0.50      0.28       179\n",
      "weighted avg       0.16      0.40      0.23       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision Recall F1-score\n",
    "results = confusion_matrix(test_labels, y_predic) \n",
    "print ('Confusion Matrix :') \n",
    "print(results) \n",
    "print ('Accuracy Score is', accuracy_score(test_labels, y_predic)) \n",
    "print('F1-score: {:.2f}\\n'.format(f1_score(test_labels, y_predic)))\n",
    "print ('Classification Report : ') \n",
    "print (classification_report(test_labels, y_predic))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
